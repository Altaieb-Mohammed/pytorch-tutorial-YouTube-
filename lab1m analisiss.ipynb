{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVRQ3FK+Gtefdmvutx7xCj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Altaieb-Mohammed/pytorch-tutorial-YouTube-/blob/main/lab1m%20analisiss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import warnings\n",
        "\n",
        "url = \"https://github.com/Altaieb-Mohammed/pytorch-tutorial-YouTube-/raw/main/synthetic_inheritance_data.csv\"\n",
        "\n",
        "df = pd.read_csv(url)\n",
        "print(df.head(6))\n"
      ],
      "metadata": {
        "id": "AQ4ma0TMoWH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTfW3Gxfjk6j"
      },
      "outputs": [],
      "source": [
        "#---------------------------------------------------------- Лабораторная работа №1:\n",
        "\n",
        "# --- Загрузить данные из GitHub----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "url = \"https://github.com/Altaieb-Mohammed/pytorch-tutorial-YouTube-/raw/main/synthetic_inheritance_data.csv\"\n",
        "\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# --- проверка признаков----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "\n",
        "# Использование реальных имен столбцов из нашего набора данных----------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "numeric_features = [\n",
        "    'debts', 'funeral_expenses', 'bequests', 'wife', 'husband', 'son', 'daughter',\n",
        "    'father', 'mother', 'brother', 'sister', 'grandchild'\n",
        "]\n",
        "\n",
        "# ---  Чистые данные---\n",
        "# Удалить строки с отсутствующими значениями в числовых столбцах------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "df_clean = df[numeric_features].dropna()\n",
        "\n",
        "# удалить строки с неположительными значениями в финансовых столбцах.----------------------------------------------------------------------------------------------------------------------------------------------\n",
        "for col in ['debts', 'funeral_expenses', 'bequests']:\n",
        "    df_clean = df_clean[df_clean[col] > 0]\n",
        "\n",
        "# --- Масштабирование ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "# Min-Max Scaling\n",
        "minmax_scaler = MinMaxScaler()\n",
        "df_minmax = pd.DataFrame(\n",
        "    minmax_scaler.fit_transform(df_clean),\n",
        "    columns=numeric_features\n",
        ")\n",
        "\n",
        "# Standard Scaling------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "standard_scaler = StandardScaler()\n",
        "df_standard = pd.DataFrame(\n",
        "    standard_scaler.fit_transform(df_clean),\n",
        "    columns=numeric_features\n",
        ")\n",
        "\n",
        "# ---  результаты  ------------------------------------------------------------------------------------------------------------\n",
        "df_clean.to_csv('inheritance_cleaned.csv', index=False)\n",
        "df_minmax.to_csv('inheritance_minmax_scaled.csv', index=False)\n",
        "df_standard.to_csv('inheritance_standard_scaled.csv', index=False)\n",
        "\n",
        "# ---  Preview ---------------------------------------------------------------------------------------------  Preview------------------------------------------------------------------------------------------------------\n",
        "print(\"Cleaned data:\\n\", df_clean.head())\n",
        "print(\"MinMax scaled:\\n\", df_minmax.head())\n",
        "print(\"Standard scaled:\\n\", df_standard.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------------Лабораторная работа №2: Анализ распределений и корреляций\n",
        "# ---  Загрузка данных ---\n",
        "url = \"https://github.com/Altaieb-Mohammed/pytorch-tutorial-YouTube-/raw/main/synthetic_inheritance_data.csv\"\n",
        "df = pd.read_csv(url)\n",
        "# ---  Определение числовых и категориальных признаков -----------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "# Числовые признаки (финансовые и количественные)\n",
        "numerical_features = [\n",
        "    'debts', 'funeral_expenses', 'bequests', 'wife', 'husband', 'son', 'daughter',\n",
        "    'father', 'mother', 'brother', 'sister', 'grandchild'\n",
        "]\n",
        "\n",
        "# Категориальные признаки (в данном датасете только текстовое описание)--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "categorical_features = ['text']\n",
        "\n",
        "# ---  Очистка числовых данных от пропусков -----------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "df_num = df[numerical_features].dropna()\n",
        "\n",
        "# ---  Анализ распределения числовых признаков -----------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "for feature in numerical_features:\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Гистограмма распределения--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.histplot(df_num[feature], bins=30, kde=False)\n",
        "    plt.title(f'Гистограмма распределения: {feature}')\n",
        "    plt.xlabel(feature)\n",
        "    plt.ylabel('Частота')\n",
        "\n",
        "    # График плотности--------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "    plt.subplot(1, 2, 2)\n",
        "    sns.kdeplot(df_num[feature], fill=True)\n",
        "    plt.title(f'График плотности: {feature}')\n",
        "    plt.xlabel(feature)\n",
        "    plt.ylabel('Плотность')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ---  Диаграммы \"ящик с усами\" для выявления выбросов -----------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "for feature in numerical_features:\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.boxplot(x=df_num[feature])\n",
        "    plt.title(f'Диаграмма \"ящик с усами\": {feature}')\n",
        "    plt.xlabel(feature)\n",
        "    plt.show()\n",
        "\n",
        "# --- Анализ распределения категориальных признаков -----------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "# Для текстового поля можно вывести несколько примеров и длину текста\n",
        "print(\"\\nПримеры текстовых описаний:\")\n",
        "print(df['text'].head(5))\n",
        "df['text_length'] = df['text'].apply(len)\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.histplot(df['text_length'], bins=30)\n",
        "plt.title('Распределение длины текстовых описаний')\n",
        "plt.xlabel('Длина текста')\n",
        "plt.ylabel('Частота')\n",
        "plt.show()\n",
        "\n",
        "# ---  Анализ взаимосвязей (корреляций) числовых признаков -----------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(df_num.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Матрица корреляций числовых признаков')\n",
        "plt.show()\n",
        "\n",
        "# --- Краткие выводы ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "print(\"Краткие статистики по числовым признакам:\\n\", df_num.describe())\n",
        "\n",
        "# Пример анализа:\n",
        "# - Высокая корреляция между количеством сыновей и дочерей может указывать на большие семьи.\n",
        "# - Финансовые признаки (долги, расходы на похороны, завещания) могут быть скоррелированы между собой.\n",
        "# - Выбросы в признаках debts, bequests и funeral_expenses могут указывать на редкие, но крупные случаи.\n",
        "\n"
      ],
      "metadata": {
        "id": "0Y93w1tPmN60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jOUhCj1Bobt",
        "outputId": "d77cdc4c-d4d2-4d48-c762-65a540f8d3a6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#---------------------------------------------------------- Лабораторная работа №3:\n",
        "# ------------------------------------------\n",
        "# 1. Загрузка и предварительный анализ данных\n",
        "# ------------------------------------------\n",
        "import numpy as np\n",
        "\n",
        "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "try:\n",
        "    url = \"https://github.com/Altaieb-Mohammed/pytorch-tutorial-YouTube-/raw/main/synthetic_inheritance_data.csv\"\n",
        "    df = pd.read_csv(url)\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка загрузки данных: {e}\")\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    df = pd.read_csv(next(iter(uploaded)))\n",
        "\n",
        "# Выбор и проверка признаков\n",
        "feature_columns = [\n",
        "    'debts', 'funeral_expenses', 'bequests', 'wife', 'husband',\n",
        "    'son', 'daughter', 'father', 'mother', 'brother', 'sister', 'grandchild'\n",
        "]\n",
        "\n",
        "# Очистка данных\n",
        "df_clean = df[feature_columns].dropna()\n",
        "\n",
        "# ------------------------------------------\n",
        "# 2. Расширенная визуализация данных\n",
        "# ------------------------------------------\n",
        "# Распределение ключевых финансовых признаков\n",
        "plt.figure(figsize=(15,10))\n",
        "for i, col in enumerate(['debts', 'funeral_expenses', 'bequests'], 1):\n",
        "    plt.subplot(2,2,i)\n",
        "    sns.histplot(df_clean[col], bins=30, kde=True)\n",
        "    plt.title(f'Распределение {col}')\n",
        "    plt.xlabel('Значение')\n",
        "    plt.ylabel('Частота')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Матрица корреляций\n",
        "plt.figure(figsize=(12,8))\n",
        "corr_matrix = df_clean.corr()\n",
        "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", mask=mask)\n",
        "plt.title('Матрица корреляций признаков')\n",
        "plt.show()\n",
        "\n",
        "# ------------------------------------------\n",
        "# 3. Подготовка данных для моделирования\n",
        "# ------------------------------------------\n",
        "# Создание бинарного целевого признака (пример: высокое завещание)\n",
        "median_bequest = df_clean['bequests'].median()\n",
        "df_clean['high_bequest'] = (df_clean['bequests'] >= median_bequest).astype(int)\n",
        "\n",
        "X = df_clean.drop(columns=['high_bequest', 'bequests'])  # Исключаем целевую переменную\n",
        "y = df_clean['high_bequest']\n",
        "\n",
        "# Разделение данных\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Масштабирование\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ------------------------------------------\n",
        "# 4. Сравнение нескольких моделей\n",
        "# ------------------------------------------\n",
        "models = {\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(random_state=42, class_weight='balanced')\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    print(f'\\n{name} Classification Report:')\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Матрица ошибок\n",
        "    plt.figure(figsize=(6,4))\n",
        "    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'Матрица ошибок ({name})')\n",
        "    plt.xlabel('Предсказанный класс')\n",
        "    plt.ylabel('Истинный класс')\n",
        "    plt.show()\n",
        "\n",
        "# ------------------------------------------\n",
        "# 5. Оптимизация гиперпараметров для KNN\n",
        "# ------------------------------------------\n",
        "param_grid = {\n",
        "    'n_neighbors': range(3,15),\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan']\n",
        "}\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "best_knn = grid_search.best_estimator_\n",
        "print(f'\\nЛучшие параметры KNN: {grid_search.best_params_}')\n",
        "\n",
        "# ------------------------------------------\n",
        "# 6. Анализ важности признаков\n",
        "# ------------------------------------------\n",
        "forest = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
        "forest.fit(X_train_scaled, y_train)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "feat_importances = pd.Series(forest.feature_importances_, index=X.columns)\n",
        "feat_importances.nlargest(10).plot(kind='barh')\n",
        "plt.title('Важность признаков (Random Forest)')\n",
        "plt.xlabel('Важность')\n",
        "plt.show()\n",
        "\n",
        "# ------------------------------------------\n",
        "# 7. Расширенная визуализация с PCA и t-SNE\n",
        "# ------------------------------------------\n",
        "# PCA для 3D визуализации\n",
        "pca = PCA(n_components=3)\n",
        "X_pca = pca.fit_transform(X_train_scaled)\n",
        "\n",
        "fig = plt.figure(figsize=(12,8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "scatter = ax.scatter(X_pca[:,0], X_pca[:,1], X_pca[:,2], c=y_train, cmap='viridis')\n",
        "plt.title('3D визуализация PCA (финансовые данные)')\n",
        "plt.colorbar(scatter)\n",
        "plt.show()\n",
        "\n",
        "# t-SNE визуализация\n",
        "tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
        "X_tsne = tsne.fit_transform(X_train_scaled)\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.scatterplot(x=X_tsne[:,0], y=X_tsne[:,1], hue=y_train, palette='coolwarm', alpha=0.7)\n",
        "plt.title('t-SNE визуализация распределения классов')\n",
        "plt.xlabel('t-SNE 1')\n",
        "plt.ylabel('t-SNE 2')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lvPzPG5F_ZQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "---------------------------------------------------------- Лабораторная работа №4:\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, chi2\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ------------------------------------------\n",
        "# 1. Загрузка данных\n",
        "# ------------------------------------------\n",
        "try:\n",
        "    url = \"https://github.com/Altaieb-Mohammed/pytorch-tutorial-YouTube-/raw/main/synthetic_inheritance_data.csv\"\n",
        "    df = pd.read_csv(url)\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка загрузки данных: {e}\")\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    df = pd.read_csv(next(iter(uploaded)))\n",
        "\n",
        "print(\"Размер данных:\", df.shape)\n",
        "print(\"Пример данных:\")\n",
        "print(df.head())\n",
        "\n",
        "# ------------------------------------------\n",
        "# 2. Выбор нужных столбцов и очистка\n",
        "# ------------------------------------------\n",
        "feature_columns = [\n",
        "    'debts', 'funeral_expenses', 'bequests', 'wife', 'husband',\n",
        "    'son', 'daughter', 'father', 'mother', 'brother', 'sister', 'grandchild'\n",
        "]\n",
        "\n",
        "df_selected = df[feature_columns]\n",
        "\n",
        "# Проверяем пропуски и заполняем медианой\n",
        "df_selected.fillna(df_selected.median(), inplace=True)\n",
        "\n",
        "# ------------------------------------------\n",
        "# 3. Определение целевой переменной\n",
        "# ------------------------------------------\n",
        "# Для примера создадим бинарную целевую переменную: высокие долги или нет\n",
        "median_debts = df_selected['debts'].median()\n",
        "df_selected['high_debts'] = (df_selected['debts'] >= median_debts).astype(int)\n",
        "\n",
        "X = df_selected.drop(columns=['high_debts', 'debts'])\n",
        "y = df_selected['high_debts']\n",
        "\n",
        "# ------------------------------------------\n",
        "# 4. Разделение и масштабирование\n",
        "# ------------------------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler_std = StandardScaler()\n",
        "X_train_scaled = scaler_std.fit_transform(X_train)\n",
        "X_test_scaled = scaler_std.transform(X_test)\n",
        "\n",
        "scaler_minmax = MinMaxScaler()\n",
        "X_train_minmax = scaler_minmax.fit_transform(X_train)\n",
        "X_test_minmax = scaler_minmax.transform(X_test)\n",
        "\n",
        "# ------------------------------------------\n",
        "# 5. Функция для оценки выбора признаков и визуализации\n",
        "# ------------------------------------------\n",
        "def evaluate_feature_selection(score_func, score_func_name, X_train, X_test, y_train, y_test, feature_names, max_features=12):\n",
        "    feature_counts = list(range(1, min(X_train.shape[1], max_features) + 1))\n",
        "    scores = []\n",
        "    selected_features_dict = {}\n",
        "\n",
        "    for k in feature_counts:\n",
        "        selector = SelectKBest(score_func, k=k)\n",
        "        X_train_sel = selector.fit_transform(X_train, y_train)\n",
        "        X_test_sel = selector.transform(X_test)\n",
        "\n",
        "        model = RandomForestRegressor(random_state=42)\n",
        "        model.fit(X_train_sel, y_train)\n",
        "        y_pred = model.predict(X_test_sel)\n",
        "\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        scores.append(r2)\n",
        "\n",
        "        selected = [f for f, s in zip(feature_names, selector.get_support()) if s]\n",
        "        selected_features_dict[k] = selected\n",
        "\n",
        "    plt.figure(figsize=(10,6))\n",
        "    plt.plot(feature_counts, scores, marker='o', label=score_func_name)\n",
        "    plt.xlabel('Количество признаков')\n",
        "    plt.ylabel('R² (коэффициент детерминации)')\n",
        "    plt.title(f'Зависимость R² от количества признаков ({score_func_name})')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    return feature_counts, scores, selected_features_dict\n",
        "\n",
        "# ------------------------------------------\n",
        "# 6. Оценка с f_classif\n",
        "# ------------------------------------------\n",
        "feature_names = X.columns.tolist()\n",
        "\n",
        "fc_counts, fc_scores, fc_features = evaluate_feature_selection(\n",
        "    f_classif, 'f_classif', X_train_scaled, X_test_scaled, y_train, y_test, feature_names\n",
        ")\n",
        "\n",
        "# ------------------------------------------\n",
        "# 7. Оценка с chi2\n",
        "# ------------------------------------------\n",
        "chi_counts, chi_scores, chi_features = evaluate_feature_selection(\n",
        "    chi2, 'chi2', X_train_minmax, X_test_minmax, y_train, y_test, feature_names\n",
        ")\n",
        "\n",
        "# ------------------------------------------\n",
        "# 8. Итоговая таблица результатов\n",
        "# ------------------------------------------\n",
        "results_df = pd.DataFrame({\n",
        "    'Количество признаков': fc_counts,\n",
        "    'R² (f_classif)': fc_scores,\n",
        "    'Выбранные признаки (f_classif)': [\", \".join(fc_features[k]) for k in fc_counts],\n",
        "    'R² (chi2)': chi_scores,\n",
        "    'Выбранные признаки (chi2)': [\", \".join(chi_features[k]) for k in chi_counts],\n",
        "})\n",
        "\n",
        "print(results_df.head(10))\n",
        "\n",
        "results_df.to_csv('feature_selection_results.csv', index=False)\n",
        "print(\"Результаты сохранены в 'feature_selection_results.csv'\")\n",
        "\n",
        "# ------------------------------------------\n",
        "# 9. Важность признаков с RandomForest\n",
        "# ------------------------------------------\n",
        "model_rf = RandomForestRegressor(random_state=42)\n",
        "model_rf.fit(X_train_scaled, y_train)\n",
        "\n",
        "importances = pd.Series(model_rf.feature_importances_, index=feature_names).sort_values(ascending=True)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "importances.plot(kind='barh')\n",
        "plt.title('Важность признаков (Random Forest)')\n",
        "plt.xlabel('Важность')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "U7q8hQN3G9gy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}